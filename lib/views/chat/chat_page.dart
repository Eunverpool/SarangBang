import 'package:flutter/material.dart';
import '../chat/components/chat_bubble.dart';

import 'package:speech_to_text/speech_to_text.dart' as stt;
import 'package:flutter_tts/flutter_tts.dart';
import 'package:permission_handler/permission_handler.dart';
// ë…¹ìŒ
import 'package:record/record.dart';
import 'package:path_provider/path_provider.dart';
import 'dart:io';

import 'package:http/http.dart' as http;
import 'dart:convert';

// ê¸°ê¸° ID ê´€ë¦¬
import '/utils/device_id_manager.dart';
import 'package:intl/intl.dart';

class ChatPage extends StatefulWidget {
  const ChatPage({super.key});

  @override
  State<ChatPage> createState() => _ChatPageState();
}

class _ChatPageState extends State<ChatPage> {
  final TextEditingController _controller =
      TextEditingController(); // í…ìŠ¤íŠ¸ ì…ë ¥ í•„ë“œ ì œì–´ìš©

  bool _isListening = false; // ë§ˆì´í¬ í™œì„± ìƒíƒœ

  String _interimText = ""; // ì¤‘ê°„ ì¸ì‹ í…ìŠ¤íŠ¸
  List<Map<String, String>> _messages = []; // {message, time}

  String _currentTime() {
    final now = DateTime.now().toLocal();
    return "${now.hour.toString().padLeft(2, '0')}:${now.minute.toString().padLeft(2, '0')}";
  }

  // STT, TTS ê°ì²´ ìƒì„±
  final stt.SpeechToText _speechToText = stt.SpeechToText();
  final FlutterTts _flutterTts = FlutterTts();

  // ë…¹ìŒ ë³€ìˆ˜
  final AudioRecorder _recorder = AudioRecorder();
  String? _recordFilePath;

  bool _isCognitiveMode = false; //ì¸ì§€ ì§ˆë¬¸ ì—¬ë¶€
  bool _isRecording = false; // ë…¹ìŒ ì§„í–‰ ì—¬ë¶€

  // ì €ì¥ì—¬ë¶€ ë³€ìˆ˜
  bool _isAwaitingDiarySave = false;

  // UUID ë³€ìˆ˜
  String? _deviceId;

  @override
  void initState() {
    super.initState();
    _loadDeviceId();
  }

  Future<void> _loadDeviceId() async {
    final id = await DeviceIdManager.getOrCreateDeviceId();
    setState(() {
      _deviceId = id;
    });
  }

// GPT
  Future<String> _getGptResponse(String prompt) async {
    final url = Uri.parse('http://10.20.27.96:3000/gpt');
    try {
      print("GPT API ìš”ì²­ ì „ì†¡ ì‹œì‘");
      final response = await http.post(
        url,
        headers: {'Content-Type': 'application/json'},
        body: jsonEncode({
          'user_uuid': _deviceId, // <-- ë””ë°”ì´ìŠ¤ UUID ì¶”ê°€
          'input': prompt, // ì‚¬ìš©ì ì…ë ¥
        }),
      );
      print("GPT ì‘ë‹µ statusCode: ${response.statusCode}");
      if (response.statusCode == 200) {
        final decoded = jsonDecode(utf8.decode(response.bodyBytes));
        print("âœ… GPT ì‘ë‹µ : ${decoded['response']}");
        return decoded['response'] ?? 'ì‘ë‹µ ì—†ìŒ';
      } else {
        print("âŒ GPT ì„œë²„ ì‘ë‹µ ì—ëŸ¬: ${response.statusCode}");
        return 'ì„œë²„ ì˜¤ë¥˜';
      }
    } catch (e) {
      print("âŒ GPT í˜¸ì¶œ ì‹¤íŒ¨: $e");
      return 'ì˜¤ë¥˜ ë°œìƒ';
    }
  }

// ë…¹ìŒ ì‹œì‘ í•¨ìˆ˜
  Future<void> _startRecording() async {
    final status = await Permission.microphone.request();
    if (!status.isGranted) {
      print('âŒ ë§ˆì´í¬ ê¶Œí•œ ê±°ë¶€ë¨');
      return;
    }

    final dir = await getApplicationDocumentsDirectory();
    final filePath =
        '${dir.path}/${_deviceId}_cognitive_${DateTime.now().millisecondsSinceEpoch}.wav';

    // âœ… 1. ë…¹ìŒ ì‹œì‘
    await _recorder.start(
      const RecordConfig(
        encoder: AudioEncoder.wav,
        sampleRate: 16000, // ì•ˆì •ì ì¸ ì¸¡ì •ì„ ìœ„í•´ ì„¤ì •
        numChannels: 1,
      ),
      path: filePath,
    );

    setState(() {
      _recordFilePath = filePath;
      _isRecording = true;
    });

    print('ğŸ™ï¸ ë…¹ìŒ ì‹œì‘: $filePath');

    // âœ… 2. ë¬´ìŒ ê°ì§€ ì‹œì‘
    int silenceCount = 0;

    _recorder
        .onAmplitudeChanged(const Duration(milliseconds: 300))
        .listen((amp) async {
      if (amp != null && amp.current != null) {
        print('ğŸ§ ë°ì‹œë²¨: ${amp.current}');
        if (amp.current <= -20) {
          silenceCount++;
          if (silenceCount * 300 >= 2000) {
            print('ğŸ¤« 3ì´ˆ ì´ìƒ ë¬´ìŒ ê°ì§€ â†’ ë…¹ìŒ ì¢…ë£Œ');
            await _stopRecording();
            setState(() {
              _isRecording = false;
              _isCognitiveMode = false;
            });
          }
        } else {
          silenceCount = 0; // ì†Œë¦¬ ìˆìŒ
        }
      } else {
        print('âš ï¸ amplitude null ë˜ëŠ” ì¸¡ì • ì•ˆ ë¨');
      }
    });
  }

  Future<void> _stopRecording() async {
    final path = await _recorder.stop();
    print('âœ… ë…¹ìŒ ì™„ë£Œ: $path');
    if (path != null) {
      // Whisperì— í…ìŠ¤íŠ¸ ìš”ì²­
      final whisperText = await sendWavToWhisper(path);
      if (whisperText != null && whisperText.isNotEmpty) {
        // GPT ëŒ€í™” íë¦„ ì—°ê²°
        setState(() {
          _messages.add({
            'message': whisperText,
            'time': _currentTime(),
            'isMe': 'true',
          });
        });

        final gptResponse = await _getGptResponse(whisperText);

        setState(() {
          _messages.add({
            'message': gptResponse,
            'time': _currentTime(),
            'isMe': 'false',
          });
        });

        sendWavFile(path); // ğŸ” ì—¬ê¸°ì„œ ëª¨ë¸ì—ê²Œ wav íŒŒì¼ ì „ì†¡

        _flutterTts.setLanguage('ko-KR');
        _flutterTts.setPitch(1.0);
        _flutterTts.setSpeechRate(0.5);
        await _flutterTts.speak(gptResponse);

        // âœ… [ì €ì¥] íƒœê·¸ íƒì§€ ì¶”ê°€'
        if (gptResponse.contains("[ì €ì¥]")) {
          _flutterTts.setCompletionHandler(() {
            setState(() {
              _isAwaitingDiarySave = true;
            });
            print("ğŸ’¾ [ë…¹ìŒ í›„] ì €ì¥ ìœ ë„ íƒì§€ë¨");
            _startListening(); // TTS ëë‚˜ê³  STT ì¬ì‹œì‘
          });
        }
      } else {
        print("â— Whisperë¡œë¶€í„° í…ìŠ¤íŠ¸ë¥¼ ë°›ì§€ ëª»í•¨");
      }
    } else {
      print('âŒ ë…¹ìŒ íŒŒì¼ ê²½ë¡œê°€ nullì…ë‹ˆë‹¤.');
    }
  }

  @override
  void dispose() {
    _recorder.dispose();
    super.dispose();
  }

  Future<void> sendWavFile(String filePath) async {
    final uri = Uri.parse('https://bd9e-35-204-222-22.ngrok-free.app/predict');
    final file = File(filePath);

    var request = http.MultipartRequest('POST', uri)
      ..files.add(await http.MultipartFile.fromPath('audio', file.path));

    try {
      final response = await request.send();
      final result = await response.stream.bytesToString();

      if (response.statusCode == 200) {
        print('âœ… ëª¨ë¸ ì‘ë‹µ: $result');
        final jsonResult = jsonDecode(result);

        // ì›ë³¸ ê°’
        final dementiaRaw = jsonResult['dementia']; // "Positive" ë˜ëŠ” "Negative"
        final depressionRaw =
            jsonResult['depression']; // e.g., "Depressed" ë˜ëŠ” "Normal"

        print('ğŸ§  ì¹˜ë§¤ ë¶„ì„ ê²°ê³¼: $dementiaRaw');
        print('ğŸ˜” ìš°ìš¸ ë¶„ì„ ê²°ê³¼: $depressionRaw');

        // í•œê¸€ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        final String dementiaResult = (dementiaRaw == "Positive") ? "ì˜ì‹¬" : "ì •ìƒ";
        final String depressionResult =
            (depressionRaw == "Depressed") ? "ì˜ì‹¬" : "ì •ìƒ";

        print('ğŸ§  ì¹˜ë§¤ ë¶„ì„ ê²°ê³¼: $dementiaResult');
        print('ğŸ˜” ìš°ìš¸ ë¶„ì„ ê²°ê³¼: $depressionResult');

        // ì‘ë‹µ ê²°ê³¼ íŒŒì‹±í•´ì„œ MongoDB ì €ì¥ ë“± ì²˜ë¦¬
        await sendAnalysisToServer(
            _deviceId ?? "unknown", dementiaResult, depressionResult);
      } else {
        print('âŒ ì‹¤íŒ¨: ${response.statusCode}');
      }
    } catch (e) {
      print('âŒ ì˜¤ë¥˜ ë°œìƒ: $e');
    }
  }

  Future<void> sendAnalysisToServer(
      String uuid, String dementia, String depression) async {
    print("ğŸ“¡ ì„œë²„ì— ë¶„ì„ ê²°ê³¼ ì „ì†¡ ì¤‘...");
    final uri = Uri.parse('http://10.20.27.96:3000/dairy/analysis');
    final response = await http.post(
      uri,
      headers: {"Content-Type": "application/json"},
      body: jsonEncode({
        "user_uuid": uuid,
        "dementiaResult": dementia,
        "depressionResult": depression,
      }),
    );

    if (response.statusCode == 200) {
      print("âœ… ì €ì¥ ì„±ê³µ: ${response.body}");
    } else {
      print("âŒ ì €ì¥ ì‹¤íŒ¨: ${response.body}");
    }
  }

  Future<String?> sendWavToWhisper(String path) async {
    final uri = Uri.parse("https://181b-34-125-236-97.ngrok-free.app/stt");
    final file = File(path);

    var request = http.MultipartRequest('POST', uri)
      ..files.add(await http.MultipartFile.fromPath('audio', file.path));

    try {
      final response = await request.send();
      final result = await response.stream.bytesToString();

      if (response.statusCode == 200) {
        final decoded = jsonDecode(result);
        return decoded['text'];
      } else {
        print("âŒ Whisper ì‘ë‹µ ì˜¤ë¥˜: $result");
        return null;
      }
    } catch (e) {
      print("âŒ Whisper ìš”ì²­ ì‹¤íŒ¨: $e");
      return null;
    }
  }

  Future<void> _startListening() async {
    final microphoneStatus = await Permission.microphone.request();
    final speechStatus = await Permission.speech.request();

    if (microphoneStatus.isDenied || speechStatus.isDenied) {
      ScaffoldMessenger.of(context).showSnackBar(
        const SnackBar(content: Text('ìŒì„± ì¸ì‹ ë° ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.')),
      );
      return;
    }

    bool available = await _speechToText.initialize(
      onError: (error) => print('âŒ STT ì˜¤ë¥˜: ${error.errorMsg}'),
      onStatus: (status) => print('ğŸ¤ ìƒíƒœ: $status'),
    );

    if (available) {
      print("âœ… STT ì‚¬ìš© ê°€ëŠ¥");
      setState(() {
        _isListening = true;
        _interimText = "";
      });

      _speechToText.listen(
        localeId: 'ko_KR',
        pauseFor: const Duration(seconds: 2),
        onResult: (result) async {
          print(
              "ğŸ“ ì¸ì‹ ì¤‘: ${result.recognizedWords} (final: ${result.finalResult})");

          if (!result.finalResult) {
            setState(() {
              _interimText = result.recognizedWords;
            });
          } else {
            final userText = result.recognizedWords;

            setState(() {
              _messages.add({
                'message': userText,
                'time': _currentTime(),
                'isMe': 'true'
              });
              _interimText = "";
              _isListening = false;
            });

            _speechToText.stop();

            // ì‚¬ìš©ìì˜ ì €ì¥ ìš”êµ¬ ê°ì§€
            if (_isAwaitingDiarySave &&
                (userText.contains("ì‘") ||
                    userText.contains("ì €ì¥í•´") ||
                    userText.contains("ê·¸ë˜"))) {
              _isAwaitingDiarySave = false;
              await saveDiary();
              return; // GPT ì‘ë‹µì€ ìƒëµ
            }

            // âœ… GPT API ì—°ë™
            final gptResponse = await _getGptResponse(userText);

            // âœ… GPT ì‘ë‹µ ì €ì¥ ë° TTS ì¬ìƒ
            setState(() {
              _messages.add({
                'message': gptResponse,
                'time': _currentTime(),
                'isMe': 'false'
              });
            });

            _flutterTts.setLanguage('ko-KR');
            _flutterTts.setPitch(1.0);
            _flutterTts.setSpeechRate(0.5);
            await _flutterTts.speak(gptResponse);

            if (gptResponse.contains("[ì¸ì§€]")) {
              setState(() {
                _isCognitiveMode = true;
              });
              print("ğŸ§  ì¸ì§€ ì§ˆë¬¸ íƒì§€ë¨. ë‹¤ìŒ ì…ë ¥ì€ ë…¹ìŒ ëª¨ë“œ.");
            }
            if (gptResponse.contains("[ì €ì¥]")) {
              setState(() {
                _isAwaitingDiarySave = true;
              });
              print("ğŸ’¾ ì €ì¥ ìœ ë„ íƒì§€ë¨. ë‹¤ìŒ ì…ë ¥ì´ ì €ì¥ ì—¬ë¶€ íŒë‹¨ì— ì‚¬ìš©ë©ë‹ˆë‹¤.");
            }
          }
        },
      );
    } else {
      setState(() {
        _isListening = false;
        _interimText = "";
      });
    }
  }

  //STT ì¤‘ì§€
  void _stopListening() {
    _speechToText.stop();
    setState(() {
      _isListening = false;
      _interimText = "";
    });
  }

  String _currentQuestion = "ì˜¤ëŠ˜ì€ ì–´ë–¤ ì¼ì´ ìˆìœ¼ì…¨ë‚˜ìš”? ë‹¹ì‹ ì˜ í•˜ë£¨ ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì£¼ì„¸ìš”.";

  void _toggleListening() async {
    // _isListening ? _stopListening() : _startListening();
    if (_isCognitiveMode) {
      //  ì¸ì§€ ëª¨ë“œì—ì„œëŠ” ë§ˆì´í¬ ë²„íŠ¼ì´ ë…¹ìŒìœ¼ë¡œ ë™ì‘
      if (_isRecording) {
        await _stopRecording();
        setState(() {
          _isRecording = false;
          _isCognitiveMode = false; //ë…¹ìŒ ì¢…ë£Œì‹œ ì¸ì§€ ëª¨ë“œ í•´ì œ
        });
      } else {
        // ğŸ”¥ ìƒíƒœ ë¨¼ì € ì—…ë°ì´íŠ¸í•´ì„œ ë²„íŠ¼ ìƒ‰ ë¨¼ì € ë°”ë€Œë„ë¡
        setState(() {
          _isRecording = true;
        });
        await _startRecording();
      }
    } else {
      _isListening ? _stopListening() : _startListening();
    }
  }

  Future<void> saveDiary() async {
    if (_deviceId == null) return;

    showDialog(
      context: context,
      barrierDismissible: false,
      builder: (context) => const AlertDialog(
        content: Row(
          children: [
            CircularProgressIndicator(),
            SizedBox(width: 16),
            Expanded(child: Text("ì¼ê¸°ë¥¼ ì €ì¥ ì¤‘ì…ë‹ˆë‹¤...")),
          ],
        ),
      ),
    );

    final url = Uri.parse("http://10.20.27.96:3000/dairy");
    final response = await http.post(
      url,
      headers: {'Content-Type': 'application/json'},
      body: jsonEncode({'user_uuid': _deviceId}),
    );

    Navigator.of(context).pop();

    final decoded = jsonDecode(utf8.decode(response.bodyBytes));
    if (decoded['alreadyExists'] == true) {
      showDialog(
        context: context,
        builder: (context) => AlertDialog(
          title: const Text("ì•Œë¦¼"),
          content: const Text("ì˜¤ëŠ˜ì˜ ì¼ê¸°ëŠ” ì´ë¯¸ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\nì´í›„ ëŒ€í™”ëŠ” ì¼ê¸°ì— ë°˜ì˜ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."),
          actions: [
            TextButton(
              onPressed: () => Navigator.of(context).pop(),
              child: const Text("í™•ì¸"),
            ),
          ],
        ),
      );
    } else {
      ScaffoldMessenger.of(context).showSnackBar(
        const SnackBar(content: Text("âœ… ì˜¤ëŠ˜ì˜ ì¼ê¸°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")),
      );
    }
  }

  @override
  Widget build(BuildContext context) {
    final String formattedDate = DateFormat("Mì›” dì¼").format(DateTime.now());
    return Scaffold(
      backgroundColor: Colors.white,
      appBar: AppBar(
        title: Text("$formattedDateì˜ ê¸°ë¡"),
        backgroundColor: Colors.white,
        elevation: 0,
        centerTitle: true,
        foregroundColor: Colors.black,
        actions: [
          IconButton(
              icon: const Icon(Icons.check),
              onPressed: () async {
                await saveDiary();
              }),
        ],
      ),
      body: Column(
        children: [
          // ìƒë‹¨ ì•ˆë‚´ ë¬¸êµ¬
          const Padding(
            padding: EdgeInsets.symmetric(horizontal: 24, vertical: 16),
            child: Text(
              "ì˜¤ëŠ˜ ì¼ì–´ë‚¬ë˜ ì¼ì— ëŒ€í•´ ì €ì™€ ëŒ€í™”ë¥¼ í•˜ë©° ê¸°ë¡í•´ì£¼ì„¸ìš”.",
              style: TextStyle(fontSize: 14, color: Colors.grey),
              textAlign: TextAlign.center,
            ),
          ),

          // ì¤‘ì•™ ì˜ì—­ ì „ì²´ ë°°ê²½ í¬í•¨
          Expanded(
            child: Container(
              width: double.infinity,
              color: const Color(0xFFFFFBF7),
              padding: const EdgeInsets.symmetric(horizontal: 24, vertical: 12),
              child: SingleChildScrollView(
                reverse: true,
                child: Column(
                  crossAxisAlignment: CrossAxisAlignment.center,
                  children: [
                    // âœ… AI ì§ˆë¬¸ í…ìŠ¤íŠ¸
                    GestureDetector(
                      onTap: () {
                        _flutterTts.setLanguage('ko-KR');
                        _flutterTts.setPitch(1.0);
                        _flutterTts.setSpeechRate(0.5);
                        _flutterTts.speak(_currentQuestion);
                      },
                      child: Container(
                        width: double.infinity,
                        padding: const EdgeInsets.all(20),
                        decoration: BoxDecoration(
                          color: Colors.indigo[100],
                          borderRadius: BorderRadius.circular(12),
                        ),
                        child: Text(
                          _currentQuestion,
                          style: const TextStyle(
                            fontSize: 20,
                            color: Color(0xFF2C2C2C),
                            height: 1.5,
                          ),
                          textAlign: TextAlign.center,
                        ),
                      ),
                    ),

                    const SizedBox(height: 16),

                    ..._messages.map(
                      (msg) => Align(
                        alignment: msg['isMe'] == 'false'
                            ? Alignment.centerLeft
                            : Alignment.centerRight,
                        child: GestureDetector(
                          // âœ… í´ë¦­ ì´ë²¤íŠ¸ ì¶”ê°€
                          onTap: msg['isMe'] == 'false'
                              ? () {
                                  _flutterTts.setLanguage('ko-KR');
                                  _flutterTts.setPitch(1.0);
                                  _flutterTts.setSpeechRate(0.5);
                                  _flutterTts
                                      .speak(msg['message']!); // AI ì‘ë‹µ ì½ê¸°
                                }
                              : null, // ì‚¬ìš©ìëŠ” í´ë¦­í•´ë„ ì•„ë¬´ ë™ì‘ ì—†ìŒ

                          child: Container(
                            margin: const EdgeInsets.symmetric(vertical: 6),
                            padding: const EdgeInsets.all(12),
                            constraints: const BoxConstraints(maxWidth: 300),
                            decoration: BoxDecoration(
                              color: msg['isMe'] == 'false'
                                  ? Colors.indigo[100]
                                  : Colors.white,
                              borderRadius: BorderRadius.circular(16),
                              boxShadow: [
                                BoxShadow(
                                  color: Colors.black12,
                                  blurRadius: 4,
                                  offset: Offset(2, 2),
                                )
                              ],
                            ),
                            child: Text(
                              msg['message']!,
                              style: TextStyle(
                                //     fontSize: 20,
                                // color: Color(0xFF2C2C2C),
                                // height: 1.5,
                                height: msg['isMe'] == 'false' ? 1.5 : 1,
                                fontSize: msg['isMe'] == 'false' ? 20 : 16,
                                color: msg['isMe'] == 'false'
                                    ? Color(0xFF2C2C2C)
                                    : Colors.black87,
                              ),
                            ),
                          ),
                        ),
                      ),
                    ),

                    // âœ… ì‹¤ì‹œê°„ ì‚¬ìš©ì ì¤‘ê°„ ë©”ì‹œì§€
                    if (_interimText.isNotEmpty)
                      Align(
                        alignment: Alignment.centerRight,
                        child: Container(
                          margin: const EdgeInsets.symmetric(vertical: 6),
                          padding: const EdgeInsets.all(12),
                          constraints: const BoxConstraints(maxWidth: 300),
                          decoration: BoxDecoration(
                            color: Colors.white70,
                            borderRadius: BorderRadius.circular(16),
                          ),
                          child: Text(
                            _interimText,
                            style: const TextStyle(
                                fontSize: 16, color: Colors.black54),
                          ),
                        ),
                      ),
                  ],
                ),
              ),
            ),
          ),

          // í•˜ë‹¨ ë§ˆì´í¬ ë²„íŠ¼
          Container(
            height: 100,
            decoration: BoxDecoration(
              color: const Color.fromARGB(255, 255, 255, 255),
              border: const Border(top: BorderSide(color: Colors.grey)),
            ),
            child: Center(
              child: FloatingActionButton(
                onPressed: _toggleListening,
                backgroundColor:
                    (_isCognitiveMode && _isRecording) || _isListening
                        ? Colors.red
                        : Colors.green,
                child: Icon(
                  _isCognitiveMode && _isRecording ? Icons.mic : Icons.mic_none,
                  size: 32,
                ),
              ),
            ),
          ),
        ],
      ),
    );
  }
}
