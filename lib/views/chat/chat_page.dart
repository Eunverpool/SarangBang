import 'package:flutter/material.dart';
import '../chat/components/chat_bubble.dart';

import 'package:speech_to_text/speech_to_text.dart' as stt;
import 'package:flutter_tts/flutter_tts.dart';
import 'package:permission_handler/permission_handler.dart';
// ë…¹ìŒ
import 'package:record/record.dart';
import 'package:path_provider/path_provider.dart';
import 'dart:io';

import 'package:http/http.dart' as http;
import 'dart:convert';

// ê¸°ê¸° ID ê´€ë¦¬
import '/utils/device_id_manager.dart';
import 'package:intl/intl.dart';

class ChatPage extends StatefulWidget {
  const ChatPage({super.key});

  @override
  State<ChatPage> createState() => _ChatPageState();
}

class _ChatPageState extends State<ChatPage> {
  final TextEditingController _controller =
      TextEditingController(); // í…ìŠ¤íŠ¸ ì…ë ¥ í•„ë“œ ì œì–´ìš©

  bool _isListening = false; // ë§ˆì´í¬ í™œì„± ìƒíƒœ

  String _interimText = ""; // ì¤‘ê°„ ì¸ì‹ í…ìŠ¤íŠ¸
  List<Map<String, String>> _messages = []; // {message, time}

  String _currentTime() {
    final now = DateTime.now().toLocal();
    return "${now.hour.toString().padLeft(2, '0')}:${now.minute.toString().padLeft(2, '0')}";
  }

  // STT, TTS ê°ì²´ ìƒì„±
  final stt.SpeechToText _speechToText = stt.SpeechToText();
  final FlutterTts _flutterTts = FlutterTts();

  // ë…¹ìŒ ë³€ìˆ˜
  final AudioRecorder _recorder = AudioRecorder();
  String? _recordFilePath;

  bool _isCognitiveMode = false; //ì¸ì§€ ì§ˆë¬¸ ì—¬ë¶€
  bool _isRecording = false; // ë…¹ìŒ ì§„í–‰ ì—¬ë¶€

  // UUID ë³€ìˆ˜
  String? _deviceId;

  @override
  void initState() {
    super.initState();
    _loadDeviceId();
  }

  Future<void> _loadDeviceId() async {
    final id = await DeviceIdManager.getOrCreateDeviceId();
    setState(() {
      _deviceId = id;
    });
  }

// GPT
  Future<String> _getGptResponse(String prompt) async {
    final url = Uri.parse('http://10.20.22.219:3000/gpt');
    try {
      print("GPT API ìš”ì²­ ì „ì†¡ ì‹œì‘");
      final response = await http.post(
        url,
        headers: {'Content-Type': 'application/json'},
        body: jsonEncode({
          'user_uuid': _deviceId, // <-- ë””ë°”ì´ìŠ¤ UUID ì¶”ê°€
          'input': prompt, // ì‚¬ìš©ì ì…ë ¥
        }),
      );
      print("GPT ì‘ë‹µ statusCode: ${response.statusCode}");
      if (response.statusCode == 200) {
        final decoded = jsonDecode(utf8.decode(response.bodyBytes));
        print("âœ… GPT ì‘ë‹µ : ${decoded['response']}");
        return decoded['response'] ?? 'ì‘ë‹µ ì—†ìŒ';
      } else {
        print("âŒ GPT ì„œë²„ ì‘ë‹µ ì—ëŸ¬: ${response.statusCode}");
        return 'ì„œë²„ ì˜¤ë¥˜';
      }
    } catch (e) {
      print("âŒ GPT í˜¸ì¶œ ì‹¤íŒ¨: $e");
      return 'ì˜¤ë¥˜ ë°œìƒ';
    }
  }

// ë…¹ìŒ ì‹œì‘ í•¨ìˆ˜
  Future<void> _startRecording() async {
    final status = await Permission.microphone.request();
    if (!status.isGranted) {
      print('âŒ ë§ˆì´í¬ ê¶Œí•œ ê±°ë¶€ë¨');
      return;
    }

    final dir = await getApplicationDocumentsDirectory();
    final filePath =
        '${dir.path}/${_deviceId}_cognitive_${DateTime.now().millisecondsSinceEpoch}.wav';

    // âœ… 1. ë…¹ìŒ ì‹œì‘
    await _recorder.start(
      const RecordConfig(
        encoder: AudioEncoder.wav,
        sampleRate: 16000, // ì•ˆì •ì ì¸ ì¸¡ì •ì„ ìœ„í•´ ì„¤ì •
        numChannels: 1,
      ),
      path: filePath,
    );

    setState(() {
      _recordFilePath = filePath;
      _isRecording = true;
    });

    print('ğŸ™ï¸ ë…¹ìŒ ì‹œì‘: $filePath');

    // âœ… 2. ë¬´ìŒ ê°ì§€ ì‹œì‘
    int silenceCount = 0;

    _recorder
        .onAmplitudeChanged(const Duration(milliseconds: 300))
        .listen((amp) async {
      if (amp != null && amp.current != null) {
        print('ğŸ§ ë°ì‹œë²¨: ${amp.current}');
        if (amp.current <= -20) {
          silenceCount++;
          if (silenceCount * 300 >= 3000) {
            print('ğŸ¤« 3ì´ˆ ì´ìƒ ë¬´ìŒ ê°ì§€ â†’ ë…¹ìŒ ì¢…ë£Œ');
            await _stopRecording();
            setState(() {
              _isRecording = false;
              _isCognitiveMode = false;
            });
          }
        } else {
          silenceCount = 0; // ì†Œë¦¬ ìˆìŒ
        }
      } else {
        print('âš ï¸ amplitude null ë˜ëŠ” ì¸¡ì • ì•ˆ ë¨');
      }
    });
  }
  // Future<void> _startRecording() async {
  //   final status = await Permission.microphone.request();
  //   if (!status.isGranted) {
  //     print('âŒ ë§ˆì´í¬ ê¶Œí•œ ê±°ë¶€ë¨');
  //     return;
  //   }

  //   final dir = await getApplicationDocumentsDirectory();
  //   final filePath =
  //       '${dir.path}/${_deviceId}_cognitive_${DateTime.now().millisecondsSinceEpoch}.wav';

  //   await _recorder.start(const RecordConfig(encoder: AudioEncoder.wav),
  //       path: filePath);

  //   setState(() {
  //     _recordFilePath = filePath;
  //     _isRecording = true; // ë…¹ìŒ ì‹œì‘ ì‹œ ìƒíƒœ true
  //   });

  //   print('ğŸ™ï¸ ë…¹ìŒ ì‹œì‘: $filePath');

  //   // // ğŸ”” ì¼ì • ì‹œê°„ í›„ ìë™ ì¢…ë£Œ (ì˜ˆ: 10ì´ˆ)
  //   // Future.delayed(const Duration(seconds: 5), () async {
  //   //   await _stopRecording(); // íƒ€ì´ë¨¸ ì¢…ë£Œ
  //   //   setState(() {
  //   //     _isRecording = false;
  //   //     _isCognitiveMode = false; // ìë™ ì¢…ë£Œ ì‹œ ì¸ì§€ëª¨ë“œ í•´ì œ
  //   //   });
  //   // âœ… ë¬´ìŒ ê°ì§€ìš© ìŠ¤íŠ¸ë¦¼ ì‹œì‘
  //   int silenceCount = 0;
  //   _recorder
  //       .onAmplitudeChanged(const Duration(milliseconds: 300))
  //       .listen((amp) async {
  //     // ğŸ”Š ë°ì‹œë²¨ ê°’ì´ ë‚®ìœ¼ë©´ ë¬´ìŒìœ¼ë¡œ íŒë‹¨
  //     if (amp.current <= -40) {
  //       silenceCount++;
  //       if (silenceCount * 300 >= 3000) {
  //         print('ğŸ¤« 3ì´ˆ ì´ìƒ ë¬´ìŒ ê°ì§€ â†’ ë…¹ìŒ ì¢…ë£Œ');
  //         await _stopRecording();
  //         setState(() {
  //           _isRecording = false;
  //           _isCognitiveMode = false;
  //         });
  //       }
  //     } else {
  //       silenceCount = 0; // ì†Œë¦¬ ìˆìœ¼ë©´ ë¦¬ì…‹
  //     }
  //   });
  // }

  Future<void> _stopRecording() async {
    final path = await _recorder.stop();
    print('âœ… ë…¹ìŒ ì™„ë£Œ: $path');
  }

  @override
  void dispose() {
    _recorder.dispose();
    super.dispose();
  }

  Future<void> saveChatToServer(
      String uuId, String userMsg, String botMsg) async {
    final saveUrl = Uri.parse("http://10.20.22.219:3000/chat");

    try {
      final response = await http.post(
        saveUrl,
        headers: {'Content-Type': 'application/json'},
        body: jsonEncode({
          'user_uuid': uuId,
          'chat_date': DateFormat("yyyy-MM-dd HH:mm:ss")
              .format(DateTime.now().toLocal()),
          'messages': [
            {'role': 'user', 'content': userMsg},
            {'role': 'assistant', 'content': botMsg}
          ],
        }),
      );
      print("ğŸ’¾ Chat ì €ì¥ ì‘ë‹µ: ${response.body}");
    } catch (e) {
      print("âŒ Chat ì €ì¥ ì˜¤ë¥˜: $e");
    }
  }

  Future<void> _startListening() async {
    final microphoneStatus = await Permission.microphone.request();
    final speechStatus = await Permission.speech.request();

    if (microphoneStatus.isDenied || speechStatus.isDenied) {
      ScaffoldMessenger.of(context).showSnackBar(
        const SnackBar(content: Text('ìŒì„± ì¸ì‹ ë° ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.')),
      );
      return;
    }

    bool available = await _speechToText.initialize(
      onError: (error) => print('âŒ STT ì˜¤ë¥˜: ${error.errorMsg}'),
      onStatus: (status) => print('ğŸ¤ ìƒíƒœ: $status'),
    );

    if (available) {
      print("âœ… STT ì‚¬ìš© ê°€ëŠ¥");
      setState(() {
        _isListening = true;
        _interimText = "";
      });

      _speechToText.listen(
        localeId: 'ko_KR',
        onResult: (result) async {
          print(
              "ğŸ“ ì¸ì‹ ì¤‘: ${result.recognizedWords} (final: ${result.finalResult})");

          if (!result.finalResult) {
            setState(() {
              _interimText = result.recognizedWords;
            });
          } else {
            final userText = result.recognizedWords;

            setState(() {
              _messages.add({
                'message': userText,
                'time': _currentTime(),
                'isMe': 'true'
              });
              _interimText = "";
              _isListening = false;
            });

            _speechToText.stop();

            // âœ… GPT API ì—°ë™
            final gptResponse = await _getGptResponse(userText);

            // âœ… GPT ì‘ë‹µ ì €ì¥ ë° TTS ì¬ìƒ
            setState(() {
              _messages.add({
                'message': gptResponse,
                'time': _currentTime(),
                'isMe': 'false'
              });
            });

            _flutterTts.setLanguage('ko-KR');
            _flutterTts.setPitch(1.0);
            _flutterTts.setSpeechRate(0.5);
            await _flutterTts.speak(gptResponse);

            if (gptResponse.contains("[ì¸ì§€]")) {
              setState(() {
                _isCognitiveMode = true;
              });
              print("ğŸ§  ì¸ì§€ ì§ˆë¬¸ íƒì§€ë¨. ë‹¤ìŒ ì…ë ¥ì€ ë…¹ìŒ ëª¨ë“œ.");
            }
          }
        },
      );
    } else {
      setState(() {
        _isListening = false;
        _interimText = "";
      });
    }
  }

  //STT ì¤‘ì§€
  void _stopListening() {
    _speechToText.stop();
    setState(() {
      _isListening = false;
      _interimText = "";
    });
  }

  String _currentQuestion = "ì˜¤ëŠ˜ì€ ì–´ë–¤ ì¼ì´ ìˆìœ¼ì…¨ë‚˜ìš”? ë‹¹ì‹ ì˜ í•˜ë£¨ ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì£¼ì„¸ìš”.";

  void _toggleListening() async {
    // _isListening ? _stopListening() : _startListening();
    if (_isCognitiveMode) {
      //  ì¸ì§€ ëª¨ë“œì—ì„œëŠ” ë§ˆì´í¬ ë²„íŠ¼ì´ ë…¹ìŒìœ¼ë¡œ ë™ì‘
      if (_isRecording) {
        await _stopRecording();
        setState(() {
          _isRecording = false;
          _isCognitiveMode = false; //ë…¹ìŒ ì¢…ë£Œì‹œ ì¸ì§€ ëª¨ë“œ í•´ì œ
        });
      } else {
        // ğŸ”¥ ìƒíƒœ ë¨¼ì € ì—…ë°ì´íŠ¸í•´ì„œ ë²„íŠ¼ ìƒ‰ ë¨¼ì € ë°”ë€Œë„ë¡
        setState(() {
          _isRecording = true;
        });
        await _startRecording();
      }
    } else {
      _isListening ? _stopListening() : _startListening();
    }
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      backgroundColor: Colors.white,
      appBar: AppBar(
        title: const Text("5ì›” 2ì¼ì˜ ê¸°ë¡"),
        backgroundColor: Colors.white,
        elevation: 0,
        centerTitle: true,
        foregroundColor: Colors.black,
        actions: [
          IconButton(
              icon: const Icon(Icons.check),
              onPressed: () async {
                if (_deviceId == null) return;

                final url = Uri.parse("http://10.20.22.219:3000/dairy");
                final response = await http.post(
                  url,
                  headers: {'Content-Type': 'application/json'},
                  body: jsonEncode({'user_uuid': _deviceId}),
                );

                final decoded = jsonDecode(utf8.decode(response.bodyBytes));
                if (decoded['alreadyExists'] == true) {
                  showDialog(
                    context: context,
                    builder: (context) => AlertDialog(
                      title: const Text("ì•Œë¦¼"),
                      content: const Text(
                          "ì˜¤ëŠ˜ì˜ ì¼ê¸°ëŠ” ì´ë¯¸ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\nì´í›„ ëŒ€í™”ëŠ” ì¼ê¸°ì— ë°˜ì˜ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."),
                      actions: [
                        TextButton(
                          onPressed: () => Navigator.of(context).pop(),
                          child: const Text("í™•ì¸"),
                        ),
                      ],
                    ),
                  );
                } else {
                  ScaffoldMessenger.of(context).showSnackBar(
                    const SnackBar(content: Text("âœ… ì˜¤ëŠ˜ì˜ ì¼ê¸°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")),
                  );
                }
              }),
        ],
      ),
      body: Column(
        children: [
          // ìƒë‹¨ ì•ˆë‚´ ë¬¸êµ¬
          const Padding(
            padding: EdgeInsets.symmetric(horizontal: 24, vertical: 16),
            child: Text(
              "ì˜¤ëŠ˜ ì¼ì–´ë‚¬ë˜ ì¼ì— ëŒ€í•´ ì €ì™€ ëŒ€í™”ë¥¼ í•˜ë©° ê¸°ë¡í•´ì£¼ì„¸ìš”.",
              style: TextStyle(fontSize: 14, color: Colors.grey),
              textAlign: TextAlign.center,
            ),
          ),

          // ì¤‘ì•™ ì˜ì—­ ì „ì²´ ë°°ê²½ í¬í•¨
          Expanded(
            child: Container(
              width: double.infinity,
              color: const Color(0xFFFFFBF7),
              padding: const EdgeInsets.symmetric(horizontal: 24, vertical: 12),
              child: SingleChildScrollView(
                reverse: true,
                child: Column(
                  crossAxisAlignment: CrossAxisAlignment.center,
                  children: [
                    // âœ… AI ì§ˆë¬¸ í…ìŠ¤íŠ¸
                    GestureDetector(
                      onTap: () {
                        _flutterTts.setLanguage('ko-KR');
                        _flutterTts.setPitch(1.0);
                        _flutterTts.setSpeechRate(0.5);
                        _flutterTts.speak(_currentQuestion);
                      },
                      child: Container(
                        width: double.infinity,
                        padding: const EdgeInsets.all(20),
                        decoration: BoxDecoration(
                          color: Colors.indigo[100],
                          borderRadius: BorderRadius.circular(12),
                        ),
                        child: Text(
                          _currentQuestion,
                          style: const TextStyle(
                            fontSize: 20,
                            color: Color(0xFF2C2C2C),
                            height: 1.5,
                          ),
                          textAlign: TextAlign.center,
                        ),
                      ),
                    ),

                    const SizedBox(height: 16),

                    ..._messages.map(
                      (msg) => Align(
                        alignment: msg['isMe'] == 'false'
                            ? Alignment.centerLeft
                            : Alignment.centerRight,
                        child: GestureDetector(
                          // âœ… í´ë¦­ ì´ë²¤íŠ¸ ì¶”ê°€
                          onTap: msg['isMe'] == 'false'
                              ? () {
                                  _flutterTts.setLanguage('ko-KR');
                                  _flutterTts.setPitch(1.0);
                                  _flutterTts.setSpeechRate(0.5);
                                  _flutterTts
                                      .speak(msg['message']!); // AI ì‘ë‹µ ì½ê¸°
                                }
                              : null, // ì‚¬ìš©ìëŠ” í´ë¦­í•´ë„ ì•„ë¬´ ë™ì‘ ì—†ìŒ

                          child: Container(
                            margin: const EdgeInsets.symmetric(vertical: 6),
                            padding: const EdgeInsets.all(12),
                            constraints: const BoxConstraints(maxWidth: 300),
                            decoration: BoxDecoration(
                              color: msg['isMe'] == 'false'
                                  ? Colors.indigo[100]
                                  : Colors.white,
                              borderRadius: BorderRadius.circular(16),
                              boxShadow: [
                                BoxShadow(
                                  color: Colors.black12,
                                  blurRadius: 4,
                                  offset: Offset(2, 2),
                                )
                              ],
                            ),
                            child: Text(
                              msg['message']!,
                              style: TextStyle(
                                //     fontSize: 20,
                                // color: Color(0xFF2C2C2C),
                                // height: 1.5,
                                height: msg['isMe'] == 'false' ? 1.5 : 1,
                                fontSize: msg['isMe'] == 'false' ? 20 : 16,
                                color: msg['isMe'] == 'false'
                                    ? Color(0xFF2C2C2C)
                                    : Colors.black87,
                              ),
                            ),
                          ),
                        ),
                      ),
                    ),

                    // âœ… ì‹¤ì‹œê°„ ì‚¬ìš©ì ì¤‘ê°„ ë©”ì‹œì§€
                    if (_interimText.isNotEmpty)
                      Align(
                        alignment: Alignment.centerRight,
                        child: Container(
                          margin: const EdgeInsets.symmetric(vertical: 6),
                          padding: const EdgeInsets.all(12),
                          constraints: const BoxConstraints(maxWidth: 300),
                          decoration: BoxDecoration(
                            color: Colors.white70,
                            borderRadius: BorderRadius.circular(16),
                          ),
                          child: Text(
                            _interimText,
                            style: const TextStyle(
                                fontSize: 16, color: Colors.black54),
                          ),
                        ),
                      ),
                  ],
                ),
              ),
            ),
          ),

          // í•˜ë‹¨ ë§ˆì´í¬ ë²„íŠ¼
          Container(
            height: 100,
            decoration: BoxDecoration(
              color: const Color.fromARGB(255, 255, 255, 255),
              border: const Border(top: BorderSide(color: Colors.grey)),
            ),
            child: Center(
              child: FloatingActionButton(
                onPressed: _toggleListening,
                backgroundColor:
                    (_isCognitiveMode && _isRecording) || _isListening
                        ? Colors.red
                        : Colors.green,
                child: Icon(
                  _isCognitiveMode && _isRecording ? Icons.mic : Icons.mic_none,
                  size: 32,
                ),
              ),
            ),
          ),
        ],
      ),
    );
  }
}
